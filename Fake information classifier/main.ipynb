{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import spacy\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Custom Transformer using spaCy for lemmatization\n",
    "class SpacyLemmatizer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [self.lemmatize(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def lemmatize(self, text):\n",
    "        doc = nlp(text)\n",
    "        return \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('news_articles.csv')\n",
    "data=data.dropna()\n",
    "\n",
    "# Convert all text data to strings and handle NaN\n",
    "data['text_without_stopwords'] = data['text_without_stopwords'].astype(str)\n",
    "data['title_without_stopwords'] = data['title_without_stopwords'].astype(str)\n",
    "\n",
    "# Combine text and title into a single column\n",
    "X = data[['text_without_stopwords', 'title_without_stopwords']].agg(' '.join, axis=1)\n",
    "for datax in X.values:\n",
    "    doc=nlp(datax)\n",
    "    datax=[token.lemma_ for token in doc]\n",
    "# Build the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       print pay back money plus interest entire fami...\n",
       "1       attorney general loretta lynch plead fifth bar...\n",
       "2       red state fox news sunday reported morning ant...\n",
       "3       email kayla mueller prisoner tortured isis cha...\n",
       "4       email healthcare reform make america great sin...\n",
       "                              ...                        \n",
       "2041    check hillarythemed haunted house anticlinton ...\n",
       "2042    good samaritan wearing indian headdress disarm...\n",
       "2043    skype sex scam fortune built shame moroccan bo...\n",
       "2044    posted eddie skyhigh potency may scare away cr...\n",
       "2045    billion even known keeping supposedly deleted ...\n",
       "Length: 2045, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Real\n",
       "1       Real\n",
       "2       Real\n",
       "3       Real\n",
       "4       Real\n",
       "        ... \n",
       "2041    Real\n",
       "2042    Real\n",
       "2043    Real\n",
       "2044    Real\n",
       "2045    Real\n",
       "Name: label, Length: 2045, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.map({\n",
    "    \"Real\":1,\n",
    "    \"Fake\":0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "X=tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6235 - loss: 1.2067 - val_accuracy: 0.6680 - val_loss: 0.6825\n",
      "Epoch 2/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6009 - loss: 0.7094 - val_accuracy: 0.6738 - val_loss: 0.6479\n",
      "Epoch 3/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6166 - loss: 0.6459 - val_accuracy: 0.6934 - val_loss: 0.6352\n",
      "Epoch 4/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6987 - loss: 0.5987 - val_accuracy: 0.7148 - val_loss: 0.6263\n",
      "Epoch 5/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7477 - loss: 0.5645 - val_accuracy: 0.7559 - val_loss: 0.6300\n",
      "Epoch 6/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.5449 - val_accuracy: 0.7676 - val_loss: 0.6287\n",
      "Epoch 7/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.5043 - val_accuracy: 0.7656 - val_loss: 0.6631\n",
      "Epoch 8/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.4640 - val_accuracy: 0.7734 - val_loss: 0.6637\n",
      "Epoch 9/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.4623 - val_accuracy: 0.7969 - val_loss: 0.6610\n",
      "Epoch 10/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.4151 - val_accuracy: 0.7910 - val_loss: 0.6929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a2d34750>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input\n",
    "from keras.regularizers import l1,l2\n",
    "\n",
    "model=Sequential([\n",
    "    Input(shape=(X.shape[1],)),\n",
    "    Dense(2, kernel_regularizer=l2()),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
